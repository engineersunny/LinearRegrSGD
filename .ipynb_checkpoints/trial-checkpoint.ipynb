{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simple_linear_regr_utils import generate_data, evaluate\n",
    "import pandas as pd\n",
    "\n",
    "class SimpleLinearRegression:\n",
    "    def __init__(self, iterations=1500, lr=0.3):\n",
    "        self.iterations = iterations # number of iterations the fit method will be called\n",
    "        self.lr = lr # The learning rate\n",
    "        self.losses = [] # A list to hold the history of the calculated losses\n",
    "        self.W, self.b = None, None # the slope and the intercept of the model\n",
    "\n",
    "        \n",
    "    def __loss(self, y, y_hat):\n",
    "        #calculate the loss. use the sum of squared error formula for simplicity\n",
    "        #MSE: https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "        loss = None    \n",
    "        \n",
    "        sum = 0\n",
    "        n = len(y)\n",
    "\n",
    "        for i in range(0, n):        \n",
    "            squared_diff = (y[i]-y_hat[i])**2\n",
    "            sum = sum + squared_diff\n",
    "\n",
    "        mse = sum/n\n",
    "        loss = mse\n",
    "\n",
    "        self.losses.append(loss)\n",
    "    \n",
    "        return loss\n",
    "\n",
    "\n",
    "    def __init_weights(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X: The training set\n",
    "        \"\"\"\n",
    "        weights = np.random.normal(size=X.shape[1] + 1)\n",
    "        self.W = weights[:X.shape[1]].reshape(-1, X.shape[1])\n",
    "        self.b = weights[-1]\n",
    "        \n",
    "        print(\"init shape\\nself.W: \", self.W.shape)\n",
    "        print(\"self.b \", self.b.shape)\n",
    "\n",
    "        \n",
    "    def __sgd(self, X, y, y_hat, k=10): \n",
    "        \"\"\"\n",
    "        :param X: The training set\n",
    "        :param y: The actual output on the training set\n",
    "        :param y_hat: The predicted output on the training set\n",
    "        :return:\n",
    "            sets updated W and b to the instance Object (self)\n",
    "        \"\"\"\n",
    "        #combine x and y to sample k data points e.g. k=10 || 422,1 -> 10,1\n",
    "        #todo: sampling x and y separate with seed\n",
    "        train_data=pd.DataFrame(X)\n",
    "        train_data['target']=y\n",
    "        train_data.head(3)        \n",
    "        temp=train_data.sample(k)\n",
    "        \n",
    "        y_k=np.array(temp['target'])\n",
    "        x_k=np.array(temp.drop('target',axis=1))\n",
    "        \n",
    "        dW = np.zeros(shape=(1,1))        \n",
    "        db = 0\n",
    "        \n",
    "        # Calculating gradients for k points\n",
    "        for i in range(k):\n",
    "            y_hat_k = self.predict(x_k[i])\n",
    "\n",
    "            dW = dW + (-2)*x_k[i]*(y_k[i]-y_hat_k)\n",
    "            db = db + (-2)*(y_k[i]-y_hat_k)\n",
    "\n",
    "        #  ToDO update the self.W and self.b using the learning rate and the values for dW and db\n",
    "        # Updating W,b each iteration\n",
    "        self.W = self.W - self.lr * (dW/k)\n",
    "        self.b = self.b - self.lr * (db/k)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: The training set\n",
    "        :param y: The true output of the training set\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.__init_weights(X)\n",
    "        y_hat = self.predict(X)\n",
    "        loss = self.__loss(y, y_hat)\n",
    "        print(f\"Initial Loss: {loss}\")\n",
    "        \n",
    "        for i in range(self.iterations + 1):\n",
    "            \n",
    "            self.__sgd(X, y, y_hat) ## Updates self.W, self.b   \n",
    "            \n",
    "            y_hat = self.predict(X)            \n",
    "            loss = self.__loss(y, y_hat)\n",
    "            \n",
    "            if not i % 1000:\n",
    "                print(f\"Iteration {i}, Loss: {loss}\")\n",
    "\n",
    "                \n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        :param X: The training dataset\n",
    "        :return:\n",
    "            y_hat: the predicted output\n",
    "        \"\"\"\n",
    "        y_hat = np.dot(X,self.W) + self.b\n",
    "        \n",
    "        return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 0), dtype=float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Training Samples: 422; # Test samples: 20;\n",
      "init shape\n",
      "self.W:  (1, 1)\n",
      "self.b  ()\n",
      "Initial Loss: [29135.32943556]\n",
      "Iteration 0, Loss: [28091.06048919]\n",
      "Iteration 1000, Loss: [5791.90922236]\n",
      "Iteration 2000, Loss: [5625.40980321]\n",
      "Iteration 3000, Loss: [5472.4584612]\n",
      "Iteration 4000, Loss: [5339.25623734]\n",
      "Iteration 5000, Loss: [5218.62122544]\n",
      "Iteration 6000, Loss: [5124.88122286]\n",
      "Iteration 7000, Loss: [5013.11943402]\n",
      "Iteration 8000, Loss: [4915.59315539]\n",
      "Iteration 9000, Loss: [4834.27899624]\n",
      "Iteration 10000, Loss: [4756.47924922]\n",
      "Iteration 11000, Loss: [4703.16857287]\n",
      "Iteration 12000, Loss: [4629.857763]\n",
      "Iteration 13000, Loss: [4569.01660096]\n",
      "Iteration 14000, Loss: [4517.59645507]\n",
      "Iteration 15000, Loss: [4473.01144974]\n",
      "Iteration 16000, Loss: [4423.28955552]\n",
      "Iteration 17000, Loss: [4397.20670426]\n",
      "Iteration 18000, Loss: [4356.72279566]\n",
      "Iteration 19000, Loss: [4311.57029309]\n",
      "Iteration 20000, Loss: [4299.51101108]\n",
      "Iteration 21000, Loss: [4263.16399583]\n",
      "Iteration 22000, Loss: [4224.93813189]\n",
      "Iteration 23000, Loss: [4200.78127487]\n",
      "Iteration 24000, Loss: [4182.05960149]\n",
      "Iteration 25000, Loss: [4159.60798361]\n",
      "Iteration 26000, Loss: [4148.9175022]\n",
      "Iteration 27000, Loss: [4127.78228333]\n",
      "Iteration 28000, Loss: [4112.5902728]\n",
      "Iteration 29000, Loss: [4099.08094162]\n",
      "Iteration 30000, Loss: [4087.30466122]\n",
      "Iteration 31000, Loss: [4072.26541288]\n",
      "Iteration 32000, Loss: [4070.6311563]\n",
      "Iteration 33000, Loss: [4053.22344138]\n",
      "Iteration 34000, Loss: [4045.55071063]\n",
      "Iteration 35000, Loss: [4046.8786185]\n",
      "Iteration 36000, Loss: [4036.62409236]\n",
      "Iteration 37000, Loss: [4029.0169145]\n",
      "Iteration 38000, Loss: [4019.31558635]\n",
      "Iteration 39000, Loss: [4012.87957114]\n",
      "Iteration 40000, Loss: [4010.82274178]\n",
      "Iteration 41000, Loss: [4024.6005449]\n",
      "Iteration 42000, Loss: [4009.82478435]\n",
      "Iteration 43000, Loss: [3998.91612377]\n",
      "Iteration 44000, Loss: [3997.02387993]\n",
      "Iteration 45000, Loss: [3990.71049378]\n",
      "Iteration 46000, Loss: [3987.22019791]\n",
      "Iteration 47000, Loss: [3989.5201365]\n",
      "Iteration 48000, Loss: [3983.38493869]\n",
      "Iteration 49000, Loss: [3979.23476574]\n",
      "Iteration 50000, Loss: [3976.9906821]\n",
      "Iteration 51000, Loss: [3980.64200858]\n",
      "Iteration 52000, Loss: [3974.41970136]\n",
      "Iteration 53000, Loss: [3971.81034039]\n",
      "Iteration 54000, Loss: [3970.86659331]\n",
      "Iteration 55000, Loss: [3975.97367473]\n",
      "Iteration 56000, Loss: [3967.99541731]\n",
      "Iteration 57000, Loss: [3968.7057944]\n",
      "Iteration 58000, Loss: [3966.16429727]\n",
      "Iteration 59000, Loss: [3970.8141817]\n",
      "Iteration 60000, Loss: [3970.53003475]\n",
      "Iteration 61000, Loss: [3964.05855051]\n",
      "Iteration 62000, Loss: [3969.57823353]\n",
      "Iteration 63000, Loss: [3974.02095335]\n",
      "Iteration 64000, Loss: [3961.04034985]\n",
      "Iteration 65000, Loss: [3961.07487386]\n",
      "Slope: [[888.72109482]]; Intercept: [152.23355188]\n",
      "Mean squared error: 2584.94\n",
      "Coefficient of determination: 0.46\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Success ******\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = generate_data()\n",
    "model = SimpleLinearRegression()\n",
    "\n",
    "model.iterations = 65000\n",
    "model.lr=0.01\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "evaluate(model, X_test, y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save params\n",
    "\n",
    "import pickle\n",
    "\n",
    "res = True\n",
    "try:\n",
    "    with open('file_w.pickle', 'wb') as handle:\n",
    "        pickle.dump(model.W, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('file_b.pickle', 'wb') as handle:\n",
    "        pickle.dump(model.b, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "except Exception as err:\n",
    "    res = False\n",
    "    \n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
